# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/7. Pipeline.ipynb.

# %% auto 0
__all__ = ['Pipeline']

# %% ../nbs/7. Pipeline.ipynb 1
import torch
from torch import Tensor
from whisperspeech.t2s_up_wds_mlang_enclm import TSARTransformer
from whisperspeech.s2a_delar_mup_wds_mlang import SADelARTransformer
from whisperspeech.a2wav import Vocoder
from whisperspeech import inference
import traceback
from pathlib import Path
from os.path import expanduser
from typing import Optional, Callable, Union

# %% ../nbs/7. Pipeline.ipynb 2
class Pipeline:
    default_speaker = torch.tensor(
       [-0.2929, -0.4503,  0.4155, -0.1417,  0.0473, -0.1624, -0.2322,  0.7071,
         0.4800,  0.5496,  0.0410,  0.6236,  0.4729,  0.0587,  0.2194, -0.0466,
        -0.3036,  0.0497,  0.5028, -0.1703,  0.5039, -0.6464,  0.3857, -0.7350,
        -0.1605,  0.4808,  0.5397, -0.4851,  0.1774, -0.8712,  0.5789,  0.1785,
        -0.1417,  0.3039,  0.4232, -0.0186,  0.2685,  0.6153, -0.3103, -0.5706,
        -0.4494,  0.3394, -0.6184, -0.3617,  1.1041, -0.1178, -0.1885,  0.1997,
         0.5571, -0.2906, -0.0477, -0.4048, -0.1062,  1.4779,  0.1639, -0.3712,
        -0.1776, -0.0568, -0.6162,  0.0110, -0.0207, -0.1319, -0.3854,  0.7248,
         0.0343,  0.5724,  0.0670,  0.0486, -0.3813,  0.1738,  0.3017,  1.0502,
         0.1550,  0.5708,  0.0366,  0.5093,  0.0294, -0.7091, -0.8220, -0.1583,
        -0.2343,  0.1366,  0.7372, -0.0631,  0.1505,  0.4600, -0.1252, -0.5245,
         0.7523, -0.0386, -0.2587,  1.0066, -0.2037,  0.1617, -0.3800,  0.2790,
         0.0184, -0.5111, -0.7291,  0.1627,  0.2367, -0.0192,  0.4822, -0.4458,
         0.1457, -0.5884,  0.1909,  0.2563, -0.2035, -0.0377,  0.7771,  0.2139,
         0.3801,  0.6047, -0.6043, -0.2563, -0.0726,  0.3856,  0.3217,  0.0823,
        -0.1302,  0.3287,  0.5693,  0.2453,  0.8231,  0.0072,  1.0327,  0.6065,
        -0.0620, -0.5572,  0.5220,  0.2485,  0.1520,  0.0222, -0.2179, -0.7392,
        -0.3855,  0.1822,  0.1042,  0.7133,  0.3583,  0.0606, -0.0424, -0.9189,
        -0.4882, -0.5480, -0.5719, -0.1660, -0.3439, -0.5814, -0.2542,  0.0197,
         0.4942,  0.0915, -0.0420, -0.0035,  0.5578,  0.1051, -0.0891,  0.2348,
         0.6876, -0.6685,  0.8215, -0.3692, -0.3150, -0.0462, -0.6806, -0.2661,
        -0.0308, -0.0050,  0.6756, -0.1647,  1.0734,  0.0049,  0.4969,  0.0259,
        -0.8949,  0.0731,  0.0886,  0.3442, -0.1433, -0.6804,  0.2204,  0.1859,
         0.2702,  0.1699, -0.1443, -0.9614,  0.3261,  0.1718,  0.3545, -0.0686]
    )
    
    def __init__(self, t2s_ref: Optional[str] = None, s2a_ref: Optional[str] = None, optimize: bool = True, torch_compile: bool = False, device: Optional[str] = None) -> None:
        """
        Initializes the Pipeline class with models for text-to-speech and speech-to-audio processing.

        This constructor loads and optionally optimizes the models for text-to-speech (T2S) and
        speech-to-audio (S2A) transformations. It sets up the device for computation and handles
        model optimization if requested.

        Args:
            t2s_ref (Optional[str]): A reference to the text-to-speech model. Default is None.
            s2a_ref (Optional[str]): A reference to the speech-to-audio model. Default is None.
            optimize (bool): A flag indicating whether to optimize the loaded models. Default is True.
            torch_compile (bool): A flag indicating whether to use TorchScript for model optimization. Default is False.
            device (Optional[str]): The device to run the models on. If None, automatically selects the device.

        Raises:
            Exception: If there is an issue loading the models, an exception will be printed to stdout.
        """
        if device is None: device = inference.get_compute_device()
        self.device = device
        args = dict()
        try:
            if t2s_ref:
                args["ref"] = t2s_ref
            self.t2s = TSARTransformer.load_model(**args, device=device)  # use obtained compute device
            if optimize: self.t2s.optimize(torch_compile=torch_compile)
        except:
            print("Failed to load the T2S model:")
            print(traceback.format_exc())
        try:
            if s2a_ref:
                args["ref"] = s2a_ref
            self.s2a = SADelARTransformer.load_model(**args, device=device)  # use obtained compute device
            if optimize: self.s2a.optimize(torch_compile=torch_compile)
        except:
            print("Failed to load the S2A model:")
            print(traceback.format_exc())

        self.vocoder = Vocoder(device=device)
        self.encoder = None

    def extract_spk_emb(self, fname: str) -> Tensor:
        """
        Extracts speaker embeddings from an audio file.

        This method extracts embeddings for the speaker from the first 30 seconds of the given audio file.
        It normalizes the audio samples and computes the embeddings using a pretrained encoder.

        Args:
            fname (str): The filename or path of the audio file from which to extract speaker embeddings.

        Returns:
            Tensor: A tensor representing the extracted speaker embeddings.
        """
        import torchaudio
        if self.encoder is None:
            device = self.device
            if device == 'mps': device = 'cpu' # operator 'aten::_fft_r2c' is not currently implemented for the MPS device
            from speechbrain.pretrained import EncoderClassifier
            self.encoder = EncoderClassifier.from_hparams("speechbrain/spkrec-ecapa-voxceleb",
                                                          savedir = expanduser("~/.cache/speechbrain/"),
                                                          run_opts={"device": device})
        audio_info = torchaudio.info(fname)
        actual_sample_rate = audio_info.sample_rate
        num_frames = actual_sample_rate * 30 # specify 30 seconds worth of frames
        samples, sr = torchaudio.load(fname, num_frames=num_frames)
        samples = samples[:, :num_frames]
        samples = self.encoder.audio_normalizer(samples[0], sr)
        spk_emb = self.encoder.encode_batch(samples.unsqueeze(0))
        
        return spk_emb[0,0].to(self.device)

    def set_default_speaker(self, speaker: str) -> None:
        """
        Sets the default speaker for the pipeline.

        This method allows users to specify a default speaker whose embeddings will be used for
        audio generation tasks. It is particularly useful for scenarios where the same speaker's
        voice is used repeatedly, optimizing the process by extracting speaker embeddings only once.

        Args:
            speaker (str): The filename or URI for the speaker whose embeddings are to be extracted 
                          and set as the default.

        Returns:
            None
        """      
        self.default_speaker = self.extract_spk_emb(speaker)

    def generate_atoks(self, text: str, speaker: Optional[Union[str, Path]] = None, lang: str = 'en', cps: int = 15, step_callback: Optional[Callable] = None) -> Tensor:
        """
        Generates audio tokens from text using specified speaker embeddings.

        This function converts input text into speech tokens and then to audio tokens, considering
        the specified speaker's voice. If no speaker is specified, it uses the default speaker set
        for the pipeline.

        Args:
            text (str): The input text to convert to audio tokens.
            speaker (Optional[Union[str, Path]]): The speaker identifier or path. If None, uses the default speaker.
            lang (str): The language of the input text. Default is 'en'.
            cps (int): Characters per second, controlling the speech speed. Default is 15.
            step_callback (Optional[Callable]): An optional callback function for progress tracking.

        Returns:
            Tensor: A tensor of audio tokens representing the generated speech.
        """        
        if speaker is None: speaker = self.default_speaker
        elif isinstance(speaker, (str, Path)): speaker = self.extract_spk_emb(speaker)
        text = text.replace("\n", " ")
        stoks = self.t2s.generate(text, cps=cps, lang=lang, step=step_callback)[0]
        # drop all padding tokens (they should only appear at the end)
        stoks = stoks[stoks != 512]
        atoks = self.s2a.generate(stoks, speaker.unsqueeze(0), step=step_callback)
        return atoks
        
    def generate(self, text: str, speaker: Optional[Union[str, Path]] = None, lang: str = 'en', cps: int = 15, step_callback: Optional[Callable] = None) -> Tensor:
        """
        Generates audio from text using the specified or default speaker.

        This method is a higher-level wrapper that directly converts input text into audio, leveraging
        the generate_atoks function internally. It supports customization of speech characteristics
        and optional progress tracking through a callback.

        Args:
            text (str): The text to convert to speech.
            speaker (Optional[Union[str, Path]]): The identifier or path of the speaker. Uses default if None.
            lang (str): The language of the input text. Default is 'en'.
            cps (int): Speed of speech in characters per second. Default is 15.
            step_callback (Optional[Callable]): A callback for tracking progress.

        Returns:
            Audio: An audio object containing the generated speech.
        """
        return self.vocoder.decode(self.generate_atoks(text, speaker, lang=lang, cps=cps, step_callback=step_callback))
    
    def generate_to_file(self, fname: str, text: str, speaker: Optional[Union[str, Path]] = None, lang: str = 'en', cps: int = 15, step_callback: Optional[Callable] = None) -> None:
        """
        Generates speech from text and saves it to a file.

        This method extends the generate function by saving the generated audio to the specified file.
        It offers the same flexibility in terms of speech customization and progress tracking.

        Args:
            fname (str): The filename or path where the audio should be saved.
            text (str): The text to convert to speech.
            speaker (Optional[Union[str, Path]]): The speaker identifier or path. Default speaker is used if None.
            lang (str): The language of the input text. Default is 'en'.
            cps (int): Speech speed in characters per second. Default is 15.
            step_callback (Optional[Callable]): An optional callback function for progress updates.

        Returns:
            None
        """
        self.vocoder.decode_to_file(fname, self.generate_atoks(text, speaker, lang=lang, cps=cps, step_callback=None))
        
    def generate_to_notebook(self, text: str, speaker: Optional[Union[str, Path]] = None, lang: str = 'en', cps: int = 15, step_callback: Optional[Callable] = None) -> None:
        """
        Generates and displays an audio player in Jupyter notebooks to play the generated speech.

        This function is designed for use within Jupyter notebooks, where it directly plays the generated
        audio. It provides a convenient method for previewing speech synthesis results in interactive environments.

        Args:
            text (str): The text to synthesize.
            speaker (Optional[Union[str, Path]]): The speaker's identifier or path. Defaults to the pipeline's set speaker.
            lang (str): The language of the input text. Default is 'en'.
            cps (int): The speed of speech in characters per second. Default is 15.
            step_callback (Optional[Callable]): An optional callback for tracking progress.

        Returns:
            None
        """
        self.vocoder.decode_to_notebook(self.generate_atoks(text, speaker, lang=lang, cps=cps, step_callback=None))

    def generate_to_playback(self, text: str, speaker: Optional[Union[str, Path]] = None, lang: str = 'en', cps: int = 15, step_callback: Optional[Callable] = None) -> None:
        """
        Directly plays back the generated speech audio.

        This function generates speech from text and plays it back immediately using the sounddevice library.
        It's especially useful for real-time speech synthesis and testing. Note: sounddevice must be installed.

        Args:
            text (str): The text to synthesize into speech.
            speaker (Optional[Union[str, Path]]): The speaker identifier or file. If None, uses the default speaker.
            lang (str): The language of the input text. Default is 'en'.
            cps (int): The speech speed in characters per second. Default is 15.
            step_callback (Optional[Callable]): An optional callback for progress updates.

        Returns:
            None
        """
        try:
            import sounddevice as sd
        except ImportError:
            print("\033[93mThe 'sounddevice' library is required for direct text to playback functionality. Please install it using 'pip install sounddevice'.\033[0m")
            return

        self.vocoder.decode_to_playback(self.generate_atoks(text, speaker, lang=lang, cps=cps, step_callback=step_callback))
